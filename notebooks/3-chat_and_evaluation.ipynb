{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e824fd",
   "metadata": {},
   "source": [
    "\n",
    "# Building our AI Quiz and evaluating its performance\n",
    "\n",
    "Welcome to the last notebook of this workshop content we will walk you through how to build our chat web application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fc601",
   "metadata": {},
   "source": [
    "Now lets jump to our application. The purpose of this part is to give you an overview of everything you need to do to get an chat-application working.\n",
    "\n",
    "The folder chat_solution contains the app. \n",
    "\n",
    "The most important files are:\n",
    "\n",
    "- create_db.py: This file contians the document / embedding logic\n",
    "- rag.py: the logic of how call the llm with documents\n",
    "- start_streamlit.py: where our program starts, contains the ui logic and the calls to the main components\n",
    "\n",
    "\n",
    "To use our chat we first need to make sure we have documents stored in the database. Lets do it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c107c1db-f471-4ccc-8fad-e6fbe08d0eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 74 chunks of size 700 with overlap 200\n",
      "Database saved successfully\n",
      "['What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr', 'What are LLMs?\\n\\nLarge Language Models (LLMs) are trained on massive datasets of text to predict and generate language based on given prompts, learning patterns, structures, and relationships in text to produce human-like responses.\\n\\nHow do they work?\\n\\nWhat are the most known LLMs\\nGpt-X series developed by Open-AI, they are proprietary and very powerful\\nMistral Series: developed by Mistral AI, built by an eu company\\nLLamma series: developed by Meta\\n\\nClosed source vs Open source LLMs\\n\\nClosed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-dr']\n"
     ]
    }
   ],
   "source": [
    "from chat_solution.create_db import create_db\n",
    "\n",
    "db = create_db()\n",
    "print(db.retrieve(\"what is a llm?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088798a1",
   "metadata": {},
   "source": [
    "## Our RAG script\n",
    "\n",
    "The main part of this chat application is to create a rag call. The LearningAssistant in rag.py is where we implemented our main logic.\n",
    "Explore it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0362f7-abc1-4043-9ba8-a3648696e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment variables from /workspaces/ai-quiz/.env\n",
      "Question: What is a hallucination in the context of LLMs?\n",
      "1. A hallucination is when an LLM provides a response that is completely made up and not based on any real information. (CORRECT)\n",
      "2. A hallucination is when an LLM searches the internet for relevant information.\n",
      "3. A hallucination is when an LLM generates responses by using a predefined set of rules and templates.\n",
      "4. A hallucination is when an LLM learns patterns, structures, and relationships in text from massive datasets.\n"
     ]
    }
   ],
   "source": [
    "# User input and response handling\n",
    "from chat_solution.rag import LearningAssistant\n",
    "\n",
    "rag = LearningAssistant()  \n",
    "query = \"what is an hallucination?\"\n",
    "response = rag.query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc7391ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# now change teh instruc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a11c4988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A hallucination? Oh, you mean when your AI starts seeing pink elephants and talking to them? Yeah, that's not good. It's like when your model thinks it's a fortune teller and starts making stuff up. We call it \"hallucinating\" because it's not based on real facts, just like when you eat too much spicy food and start seeing things.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rag = LearningAssistant()\n",
    "rag.instructions = \"\"\" You are a unhelpful  joker assistant. Your goal go give funny answers to the user questions.\"\"\"\n",
    "query = \"what is an hallucination?\"\n",
    "response = rag.query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dcdcfe",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Tune the examples and the prompot to see if you get a better chat experience. Consider using Chain-of-Tought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8a37bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is a hallucination in the context of AI?\n",
      "1. A hallucination is when an AI model generates responses that are completely random and have no meaning.\n",
      "2. A hallucination is when an AI model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data. (CORRECT)\n",
      "3. A hallucination is when an AI model generates responses that are always 100% accurate and true.\n",
      "4. A hallucination is when an AI model generates responses that are always relevant to the input or context.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rag = LearningAssistant()\n",
    "# add your code here\n",
    "response = rag.query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865ae7c",
   "metadata": {},
   "source": [
    "\n",
    "## Running our quiz web application\n",
    "\n",
    "Now that we explored out assistant in the notebook, lets move to use it in our streamlit application.\n",
    "The code bellow starts a new streamlit (and stops if there is already another instance running).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a510adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\n",
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://10.0.1.151:8501\n",
      "  External URL: http://20.61.126.210:8501\n",
      "\n",
      "Loading environment variables from /workspaces/ai-quiz/.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 19:34:21.801 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"pkill -f stremalit \")\n",
    "os.system(\"streamlit run ../chat_solution/start_streamlit.py &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7bc4d",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Play with the chat and try suggesting some topcis for the chat and see if you get results as you expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2ddc4",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluating RAG Applications\n",
    "\n",
    "As you probably got by now, llm can go wrong in so many different ways. One key aspect of making robust ML applications (including rag) is to have proper evaluation of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1a3fc0-7d01-4dc7-b340-f9b3c6b63fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment variables from /workspaces/ai-quiz/.env\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'user_input': 'role models in the area of artificial intelligence?',\n",
       "  'reference': 'Question: Who is a prominent figure known for their influential work on AI ethics?\\n1. Chip Huyen\\n2. Timnit Gebru (CORRECT)\\n3. Andrej Karpathy\\n',\n",
       "  'response': 'Question: Who is a prominent role model in the area of artificial intelligence?\\n1. Elon Musk\\n2. Fei-Fei Li (CORRECT)\\n3. Mark Zuckerberg\\n4. Bill Gates'},\n",
       " {'user_input': 'famous books on llms',\n",
       "  'reference': 'Question: Which of the following is a famous book that discusses Large Language Models (LLMs)?\\n1. The Hitchhiker\\'s Guide to the Galaxy\" by Douglas Adams\\n2. Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (CORRECT)\\n3. 1984\" by George Orwell\\n4. To Kill a Mockingbird\" by Harper Lee\\n',\n",
       "  'response': 'Question: Which of the following is a famous book that discusses large language models (LLMs)?\\n1. \"The Catcher in the Rye\" by J.D. Salinger\\n2. \"Life 3.0: Being Human in the Age of Artificial Intelligence\" by Max Tegmark (CORRECT)\\n3. \"To Kill a Mockingbird\" by Harper Lee\\n4. \"The Great Gatsby\" by F. Scott Fitzgerald'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import EvaluationDataset\n",
    "from chat_solution.rag import LearningAssistant\n",
    "\n",
    "data = [\n",
    "     {'user_input': 'role models in the area of artificial intelligence?',\n",
    "      'reference': \"\"\"Question: Who is a prominent figure known for their influential work on AI ethics?\n",
    "1. Chip Huyen\n",
    "2. Timnit Gebru (CORRECT)\n",
    "3. Andrej Karpathy\n",
    "\"\"\"\n",
    "     },\n",
    "     {'user_input': \"famous books on llms\",\n",
    "      'reference': \"\"\"Question: Which of the following is a famous book that discusses Large Language Models (LLMs)?\n",
    "1. The Hitchhiker's Guide to the Galaxy\" by Douglas Adams\n",
    "2. Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (CORRECT)\n",
    "3. 1984\" by George Orwell\n",
    "4. To Kill a Mockingbird\" by Harper Lee\n",
    "\"\"\"\n",
    "      }\n",
    "]\n",
    "\n",
    "# augment data with the llm response\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    rag = LearningAssistant()\n",
    "    response = rag.query(d['user_input'])\n",
    "    data[i]['response'] = response\n",
    "\n",
    "\n",
    "dataset = EvaluationDataset.from_list(data)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02580cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:38<00:00, 19.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import FactualCorrectness\n",
    "from ragas import evaluate\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "factual_correctness = FactualCorrectness()\n",
    "mistral_llm = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "\n",
    "eval_results = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[factual_correctness],\n",
    "        llm=mistral_llm,\n",
    "       raise_exceptions=False \n",
    ")\n",
    "\n",
    "evaluation_result_df = eval_results.to_pandas()\n",
    "#compute average score\n",
    "evaluation_result_df['factual_correctness'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "848262de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factual correctness score:  0.165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>role models in the area of artificial intellig...</td>\n",
       "      <td>Question: Who is a prominent role model in the...</td>\n",
       "      <td>Question: Who is a prominent figure known for ...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>famous books on llms</td>\n",
       "      <td>Question: Which of the following is a famous b...</td>\n",
       "      <td>Question: Which of the following is a famous b...</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  role models in the area of artificial intellig...   \n",
       "1                               famous books on llms   \n",
       "\n",
       "                                            response  \\\n",
       "0  Question: Who is a prominent role model in the...   \n",
       "1  Question: Which of the following is a famous b...   \n",
       "\n",
       "                                           reference  factual_correctness  \n",
       "0  Question: Who is a prominent figure known for ...                 0.00  \n",
       "1  Question: Which of the following is a famous b...                 0.33  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Factual correctness score: \", evaluation_result_df['factual_correctness'].mean())\n",
    "evaluation_result_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ffe5b",
   "metadata": {},
   "source": [
    "## Task 3 Add  a new evaluation metric \n",
    "\n",
    "Look at [ragas documentation](https://docs.ragas.io/en/stable/) for more metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5597c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:29<00:00, 14.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factual correctness score:  0.165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>role models in the area of artificial intellig...</td>\n",
       "      <td>Question: Who is a prominent role model in the...</td>\n",
       "      <td>Question: Who is a prominent figure known for ...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>famous books on llms</td>\n",
       "      <td>Question: Which of the following is a famous b...</td>\n",
       "      <td>Question: Which of the following is a famous b...</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  role models in the area of artificial intellig...   \n",
       "1                               famous books on llms   \n",
       "\n",
       "                                            response  \\\n",
       "0  Question: Who is a prominent role model in the...   \n",
       "1  Question: Which of the following is a famous b...   \n",
       "\n",
       "                                           reference  factual_correctness  \n",
       "0  Question: Who is a prominent figure known for ...                 0.00  \n",
       "1  Question: Which of the following is a famous b...                 0.33  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import FactualCorrectness\n",
    "from ragas import evaluate\n",
    "factual_correctness = FactualCorrectness()\n",
    "# add a second metric here\n",
    "\n",
    "\n",
    "eval_results = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[\n",
    "                factual_correctness,\n",
    "        ],\n",
    "        llm=mistral_llm,\n",
    "       raise_exceptions=False \n",
    ")\n",
    "\n",
    "evaluation_result_df = eval_results.to_pandas()\n",
    "#compute average score\n",
    "evaluation_result_df['factual_correctness'].mean()\n",
    "# add your code here\n",
    "\n",
    "print(\"Factual correctness score: \", evaluation_result_df['factual_correctness'].mean())\n",
    "evaluation_result_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30c1b6",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Add your own rag class to the chat_solution folder and test it out in the streamlit app.\n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Create a new myrag.py file in chat_solution folder\n",
    "2. Create a class similar to the one in rag.py (including importing the llm and the vector database)\n",
    "3. Tune the prompt as you prefer\n",
    "4. Import it in start_streamlit.py\n",
    "5. Try it in the url\n",
    "6. Extra: if you have the time, play with the evaluation score with the new rag class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a89446",
   "metadata": {},
   "source": [
    "# The end!\n",
    "\n",
    "If you reached this phase congrats! You've made to the end. If you still have time you can check our challenge notebook with agents :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
